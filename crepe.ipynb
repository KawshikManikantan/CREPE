{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Sequential,Conv1d,Linear,MaxPool1d,ReLU,LogSoftmax\n",
    "from torch import flatten\n",
    "import torchmetrics\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.l0 = 1014\n",
    "    self.num_classes = 14\n",
    "    self.crepe_cnn = Sequential(\n",
    "      Conv1d(in_channels = 70,out_channels = 256,kernel_size=7),\n",
    "      ReLU(inplace=True),\n",
    "      MaxPool1d(kernel_size=3), \n",
    "      Conv1d(in_channels = 256,out_channels = 256,kernel_size=7),\n",
    "      ReLU(inplace=True),\n",
    "      MaxPool1d(kernel_size=3),\n",
    "      Conv1d(in_channels = 256,out_channels = 256,kernel_size=3),\n",
    "      ReLU(inplace=True),\n",
    "      Conv1d(in_channels = 256,out_channels = 256,kernel_size=3),\n",
    "      ReLU(inplace=True),\n",
    "      Conv1d(in_channels = 256,out_channels = 256,kernel_size=3),\n",
    "      ReLU(inplace=True),\n",
    "      Conv1d(in_channels = 256,out_channels = 256,kernel_size=3),\n",
    "      ReLU(inplace=True),\n",
    "      MaxPool1d(kernel_size=3),\n",
    "    )\n",
    "    self.crepe_dense = Sequential(\n",
    "      Linear(int((self.l0 - 96)/27)*256,1024),\n",
    "      ReLU(inplace=True),\n",
    "      Linear(1024,1024), \n",
    "      ReLU(inplace=True),\n",
    "      Linear(1024,self.num_classes),\n",
    "      LogSoftmax(dim= 1)\n",
    "    )\n",
    "    self.train_acc = torchmetrics.Accuracy()\n",
    "    self.train_prec = torchmetrics.Precision()\n",
    "    self.train_rec = torchmetrics.Recall()\n",
    "    self.train_f1 = torchmetrics.F1()\n",
    "    \n",
    "    self.val_acc = torchmetrics.Accuracy()\n",
    "    self.val_prec = torchmetrics.Precision()\n",
    "    self.val_rec = torchmetrics.Recall()\n",
    "    self.val_f1 = torchmetrics.F1()\n",
    "    \n",
    "    self.test_acc = torchmetrics.Accuracy()\n",
    "    self.test_prec = torchmetrics.Precision()\n",
    "    self.test_rec = torchmetrics.Recall()\n",
    "    self.test_f1 = torchmetrics.F1()\n",
    "  \n",
    "\n",
    "  def forward(self, x):\n",
    "      batch_size, width, height = x.size()\n",
    "      print(batch_size, width, height)\n",
    "      print(x.dtype)\n",
    "      y = self.crepe_cnn(x)\n",
    "      print('Y dimension',y.shape)\n",
    "      y = torch.flatten(y,start_dim=1)\n",
    "      z = self.crepe_dense(y)\n",
    "      print(\"Final Output\",z.shape)\n",
    "      return z\n",
    "\n",
    "  def cross_entropy_loss(self, logits, labels):\n",
    "    return F.nll_loss(logits, labels)\n",
    "\n",
    "  def training_step(self, train_batch, batch_idx):\n",
    "      x, y = train_batch\n",
    "      logits = self.forward(x)\n",
    "      loss = self.cross_entropy_loss(logits, y)\n",
    "      self.log('train_loss', loss)\n",
    "      self.train_acc(logits, y)\n",
    "      self.log('train_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "      self.train_prec(logits, y)\n",
    "      self.log('train_prec', self.train_acc, on_step=False, on_epoch=True)\n",
    "      self.train_rec(logits, y)\n",
    "      self.log('train_rec', self.train_acc, on_step=False, on_epoch=True)\n",
    "      self.train_f1(logits, y)\n",
    "      self.log('train_f1', self.train_acc, on_step=False, on_epoch=True)\n",
    "      return loss\n",
    "\n",
    "\n",
    "\n",
    "  def validation_step(self, val_batch, batch_idx):\n",
    "      x, y = val_batch\n",
    "      logits = self.forward(x)\n",
    "      loss = self.cross_entropy_loss(logits, y)\n",
    "      self.log('val_loss', loss)\n",
    "      self.val_acc(logits,y)\n",
    "      self.log('val_acc', self.val_acc, on_step=False, on_epoch=True)\n",
    "      self.val_prec(logits,y)\n",
    "      self.log('val_prec', self.val_acc, on_step=False, on_epoch=True)\n",
    "      self.val_rec(logits,y)\n",
    "      self.log('val_rec', self.val_acc, on_step=False, on_epoch=True)\n",
    "      self.val_f1(logits,y)\n",
    "      self.log('val_f1', self.val_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "  def test_step(self, test_batch, batch_idx):\n",
    "      x, y = test_batch\n",
    "      logits = self.forward(x)\n",
    "      loss = self.cross_entropy_loss(logits, y)\n",
    "      self.log('test_loss', loss)\n",
    "      self.test_acc(logits,y)\n",
    "      self.log('test_acc', self.test_acc)\n",
    "      self.test_prec(logits,y)\n",
    "      self.log('test_prec', self.test_acc)\n",
    "      self.test_rec(logits,y)\n",
    "      self.log('test_rec', self.test_acc)\n",
    "      self.test_f1(logits,y)\n",
    "      self.log('test_f1', self.test_acc)\n",
    "      \n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=5e-2)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def collate_fn(self,data):\n",
    "        from torch.nn.functional import one_hot\n",
    "        examples, labels = zip(*data)\n",
    "        labels = torch.tensor(labels)\n",
    "        batch_size = len(examples)\n",
    "        length = len(examples[0])\n",
    "        vocab_size = 70\n",
    "        features = torch.zeros((batch_size, length,vocab_size))\n",
    "        \n",
    "        for ind,example in enumerate(examples):\n",
    "            features[ind,:,:] = one_hot(example.to(torch.int64))\n",
    "\n",
    "        return torch.transpose(features,dim0=2,dim1=1).float(), labels.long()\n",
    "    \n",
    "    def setup(self, stage):    \n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        from torch.utils.data import TensorDataset, random_split\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        from collections import defaultdict\n",
    "        dataset = load_dataset(\"dbpedia_14\")\n",
    "        train = dataset['train']\n",
    "        train = train.shuffle(seed=42)[:]\n",
    "        test = dataset['test']\n",
    "        test = test.shuffle(seed=42)[:]\n",
    "        length = 1014\n",
    "        labels = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\|_@#$%^&*~`+=<>()[]{}\\n\"\n",
    "        label_dict = defaultdict(lambda:69)\n",
    "        for ind,i in enumerate(labels):\n",
    "            label_dict[i] = ind \n",
    "        train['content'] = [list(i.lower())[:length] + [' '] * (length - len(list(i.lower())[:length])) for i in tqdm(train['content'])]\n",
    "        train['content'] = [[label_dict[j] for j in i]for i in tqdm(train['content'])]\n",
    "        test['content'] = [list(i.lower())[:length] + [' '] * (length - len(list(i.lower())[:length])) for i in tqdm(test['content'])]\n",
    "        test['content'] = [[label_dict[j] for j in i]for i in tqdm(test['content'])]\n",
    "        train = TensorDataset(torch.Tensor(train['content']),torch.tensor(train['label']))\n",
    "        self.mnist_test = TensorDataset(torch.Tensor(test['content']),torch.tensor(test['label']))\n",
    "        self.mnist_train,self.mnist_val = random_split(train,[int(0.85*len(train)),len(train)-int(0.85*len(train))])\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=64,collate_fn=self.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=64,collate_fn=self.collate_fn)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=64,collate_fn=self.collate_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Reusing dataset d_bpedia14 (C:\\Users\\KAWSHIK\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e)\n",
      "100%|██████████| 2/2 [00:00<00:00, 20.88it/s]\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\KAWSHIK\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e\\cache-4f9bd4edcc24be65.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\KAWSHIK\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e\\cache-d75e0d932d1c3620.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86080cb0bf5040848ac654c387333746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d223c957e3104125aabf03abad0d2bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b240b719f744eab6395cc0152caef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef900a681f242daa4a19fe449252cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type       | Params\n",
      "--------------------------------------------\n",
      "0  | crepe_cnn   | Sequential | 1.4 M \n",
      "1  | crepe_dense | Sequential | 10.0 M\n",
      "2  | train_acc   | Accuracy   | 0     \n",
      "3  | train_prec  | Precision  | 0     \n",
      "4  | train_rec   | Recall     | 0     \n",
      "5  | train_f1    | F1         | 0     \n",
      "6  | val_acc     | Accuracy   | 0     \n",
      "7  | val_prec    | Precision  | 0     \n",
      "8  | val_rec     | Recall     | 0     \n",
      "9  | val_f1      | F1         | 0     \n",
      "10 | test_acc    | Accuracy   | 0     \n",
      "11 | test_prec   | Precision  | 0     \n",
      "12 | test_rec    | Recall     | 0     \n",
      "13 | test_f1     | F1         | 0     \n",
      "--------------------------------------------\n",
      "11.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.4 M    Total params\n",
      "45.400    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IREL\\Major Project\\ire1\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Validation sanity check:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IREL\\Major Project\\ire1\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/8751 [00:00<?, ?it/s] 64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n"
     ]
    }
   ],
   "source": [
    "data_module = MNISTDataModule()\n",
    "\n",
    "# train\n",
    "model = LightningMNISTClassifier()\n",
    "trainer = pl.Trainer(gpus= 1,max_epochs= 10000)\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(datamodule= data_module,model=model,ckpt_path=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset d_bpedia14 (C:\\Users\\KAWSHIK\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e)\n",
      "100%|██████████| 2/2 [00:00<00:00, 64.63it/s]\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\KAWSHIK\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e\\cache-4f9bd4edcc24be65.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\KAWSHIK\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e\\cache-d75e0d932d1c3620.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d5f16486504394a7d737884ab44717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a2253ef4db4b32a9f4cb118b561cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be96e154878b461d8849a80159d0216e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68546cf431a4939994c81212518240f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at d:\\Sem5\\SMAI\\lightning_logs\\version_38\\checkpoints\\epoch=9-step=1329.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at d:\\Sem5\\SMAI\\lightning_logs\\version_38\\checkpoints\\epoch=9-step=1329.ckpt\n",
      "d:\\IREL\\Major Project\\ire1\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:   1%|          | 1/157 [00:00<00:18,  8.36it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:   2%|▏         | 3/157 [00:00<00:13, 11.47it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:   3%|▎         | 5/157 [00:00<00:13, 10.89it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:   4%|▍         | 7/157 [00:00<00:23,  6.40it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:   6%|▌         | 9/157 [00:01<00:18,  8.17it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:   7%|▋         | 11/157 [00:01<00:16,  9.07it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:   8%|▊         | 13/157 [00:01<00:14,  9.72it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  10%|▉         | 15/157 [00:01<00:13, 10.28it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  11%|█         | 17/157 [00:01<00:13, 10.74it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  12%|█▏        | 19/157 [00:01<00:12, 10.94it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  13%|█▎        | 21/157 [00:02<00:12, 10.99it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  15%|█▍        | 23/157 [00:02<00:11, 11.31it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  16%|█▌        | 25/157 [00:02<00:11, 11.59it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  17%|█▋        | 27/157 [00:02<00:11, 11.58it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  18%|█▊        | 29/157 [00:02<00:11, 11.48it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  20%|█▉        | 31/157 [00:02<00:10, 11.72it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  21%|██        | 33/157 [00:03<00:10, 11.85it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  22%|██▏       | 35/157 [00:03<00:10, 12.00it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  24%|██▎       | 37/157 [00:03<00:09, 12.20it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  25%|██▍       | 39/157 [00:03<00:10, 11.76it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  26%|██▌       | 41/157 [00:03<00:09, 11.81it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  27%|██▋       | 43/157 [00:03<00:09, 12.04it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  29%|██▊       | 45/157 [00:04<00:09, 11.79it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  30%|██▉       | 47/157 [00:04<00:09, 11.82it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  31%|███       | 49/157 [00:04<00:08, 12.03it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  32%|███▏      | 51/157 [00:04<00:09, 11.69it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  34%|███▍      | 53/157 [00:04<00:08, 11.70it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  35%|███▌      | 55/157 [00:04<00:08, 11.96it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  36%|███▋      | 57/157 [00:05<00:08, 12.02it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  38%|███▊      | 59/157 [00:05<00:08, 11.80it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  39%|███▉      | 61/157 [00:05<00:08, 11.89it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  40%|████      | 63/157 [00:05<00:08, 11.69it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  41%|████▏     | 65/157 [00:05<00:07, 11.86it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  43%|████▎     | 67/157 [00:05<00:07, 11.99it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  44%|████▍     | 69/157 [00:06<00:07, 11.95it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  45%|████▌     | 71/157 [00:06<00:07, 11.75it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  46%|████▋     | 73/157 [00:06<00:07, 11.46it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  48%|████▊     | 75/157 [00:06<00:06, 11.87it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  49%|████▉     | 77/157 [00:06<00:06, 12.21it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  50%|█████     | 79/157 [00:07<00:06, 11.98it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  52%|█████▏    | 81/157 [00:07<00:06, 11.53it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  53%|█████▎    | 83/157 [00:07<00:06, 11.57it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  54%|█████▍    | 85/157 [00:07<00:06, 11.41it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  55%|█████▌    | 87/157 [00:07<00:06, 10.96it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  57%|█████▋    | 89/157 [00:07<00:06, 11.31it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  58%|█████▊    | 91/157 [00:08<00:05, 11.04it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  59%|█████▉    | 93/157 [00:08<00:05, 10.82it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  61%|██████    | 95/157 [00:08<00:05, 10.76it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  62%|██████▏   | 97/157 [00:08<00:05, 10.77it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  63%|██████▎   | 99/157 [00:08<00:05,  9.94it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  64%|██████▍   | 101/157 [00:09<00:05,  9.77it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  65%|██████▍   | 102/157 [00:09<00:05,  9.53it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  66%|██████▌   | 103/157 [00:09<00:05,  9.37it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  66%|██████▌   | 104/157 [00:09<00:05,  9.16it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  67%|██████▋   | 105/157 [00:09<00:05,  8.90it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  68%|██████▊   | 106/157 [00:09<00:05,  9.05it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  69%|██████▉   | 108/157 [00:09<00:05,  9.17it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  69%|██████▉   | 109/157 [00:10<00:05,  9.19it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  71%|███████   | 111/157 [00:10<00:04, 10.57it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  72%|███████▏  | 113/157 [00:10<00:03, 11.37it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  73%|███████▎  | 115/157 [00:10<00:03, 12.18it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  75%|███████▍  | 117/157 [00:10<00:03, 12.67it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  76%|███████▌  | 119/157 [00:10<00:02, 13.02it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  77%|███████▋  | 121/157 [00:10<00:02, 13.29it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  78%|███████▊  | 123/157 [00:11<00:02, 13.65it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  80%|███████▉  | 125/157 [00:11<00:02, 14.21it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  81%|████████  | 127/157 [00:11<00:02, 14.34it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  82%|████████▏ | 129/157 [00:11<00:01, 14.09it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  83%|████████▎ | 131/157 [00:11<00:01, 14.01it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  85%|████████▍ | 133/157 [00:11<00:01, 14.01it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  86%|████████▌ | 135/157 [00:11<00:01, 14.20it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  87%|████████▋ | 137/157 [00:12<00:01, 14.03it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  89%|████████▊ | 139/157 [00:12<00:01, 14.36it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  90%|████████▉ | 141/157 [00:12<00:01, 14.47it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  91%|█████████ | 143/157 [00:12<00:00, 14.84it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  92%|█████████▏| 145/157 [00:12<00:00, 15.23it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  94%|█████████▎| 147/157 [00:12<00:00, 15.09it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  95%|█████████▍| 149/157 [00:12<00:00, 14.88it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  96%|█████████▌| 151/157 [00:12<00:00, 14.60it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  97%|█████████▋| 153/157 [00:13<00:00, 14.69it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "Testing:  99%|█████████▊| 155/157 [00:13<00:00, 14.92it/s]64 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([64, 256, 34])\n",
      "Final Output torch.Size([64, 14])\n",
      "16 70 1014\n",
      "torch.float32\n",
      "Y dimension torch.Size([16, 256, 34])\n",
      "Final Output torch.Size([16, 14])\n",
      "Testing: 100%|██████████| 157/157 [00:13<00:00, 12.62it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.07240000367164612,\n",
      " 'test_f1': 0.07240000367164612,\n",
      " 'test_loss': 2.6409757137298584,\n",
      " 'test_prec': 0.07240000367164612,\n",
      " 'test_rec': 0.07240000367164612}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 157/157 [00:13<00:00, 11.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2.6409757137298584,\n",
       "  'test_acc': 0.07240000367164612,\n",
       "  'test_prec': 0.07240000367164612,\n",
       "  'test_rec': 0.07240000367164612,\n",
       "  'test_f1': 0.07240000367164612}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(data):\n",
    "#     \"\"\"\n",
    "#        data: is a list of tuples with (example, label, length)\n",
    "#              where 'example' is a tensor of arbitrary shape\n",
    "#              and label/length are scalars\n",
    "#     \"\"\"\n",
    "#     print(data)\n",
    "#     from torch.nn.functional import one_hot\n",
    "#     examples, labels = zip(*data)\n",
    "#     labels = torch.tensor(labels)\n",
    "#     batch_size = len(examples)\n",
    "#     length = len(examples[0])\n",
    "#     vocab_size = 70\n",
    "#     features = torch.zeros((batch_size, length,vocab_size))\n",
    "    \n",
    "#     for ind,example in enumerate(examples):\n",
    "#         features[ind,:,:] = one_hot(example.to(torch.int64))\n",
    "        \n",
    "#     return features.float(), labels.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import label_binarize\n",
    "# from torch.utils.data import TensorDataset, random_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from collections import defaultdict\n",
    "# dataset = load_dataset(\"dbpedia_14\")\n",
    "# train = dataset['train']\n",
    "# train = train.shuffle(seed=42)[:10]\n",
    "# test = dataset['test']\n",
    "# test = test.shuffle(seed=42)[:10]\n",
    "# length = 1014\n",
    "# labels = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\|_@#$%^&*~`+=<>()[]{}\\n\"\n",
    "# label_dict = defaultdict(lambda:69)\n",
    "# for ind,i in enumerate(labels):\n",
    "#     label_dict[i] = ind \n",
    "# train['content'] = [list(i.lower())[:length] + [' '] * (length - len(list(i.lower())[:length])) for i in tqdm(train['content'])]\n",
    "# train['content'] = [[ label_dict[j] for j in i]for i in tqdm(train['content'])]\n",
    "# len(train['content']),len(train['content'][0])\n",
    "# # test['content'] = [list(i.lower())[:length] + [' '] * (length - len(list(i.lower())[:length])) for i in tqdm(test['content'])]\n",
    "# # train['content'] = []\n",
    "# # label_encoder = LabelEncoder()\n",
    "# # y = label_encoder.fit_transform()\n",
    "# # train['content'] = [label_binarize(i,classes=labels) for i in tqdm(train['content'])]\n",
    "# # train['content'] = torch.tensor(np.array(train['content']))\n",
    "# # test['content'] = [label_binarize(i,classes=labels) for i in tqdm(test['content'])]\n",
    "# # test['content'] = torch.tensor(np.array(train['content']))\n",
    "\n",
    "# # print(torch.transpose(train['content'],dim0=2,dim1=1).float().shape)\n",
    "# # print(torch.tensor(train['label']).shape)\n",
    "# # print(torch.transpose(test['content'],dim0=2,dim1=1).float().shape)\n",
    "# # print(torch.tensor(test['label']).shape)\n",
    "\n",
    "# # torch.save(torch.transpose(train['content'],dim0=2,dim1=1).float(), 'traincontent.pt')\n",
    "# # torch.save(torch.tensor(train['label']),'trainlabel.pt')\n",
    "# # torch.save(torch.transpose(test['content'],dim0=2,dim1=1).float(),'testcontent.pt')\n",
    "# # torch.save(torch.tensor(test['label']),'testlabel.pt')\n",
    "\n",
    "# train = TensorDataset(torch.Tensor(train['content']),torch.tensor(train['label']))\n",
    "# # train = TensorDataset(torch.transpose(train['content'],dim0=2,dim1=1).float(),torch.tensor(train['label']))\n",
    "# # mnist_test = TensorDataset(torch.transpose(test['content'],dim0=2,dim1=1).float(),torch.tensor(test['label']))\n",
    "# # mnist_train,mnist_val = random_split(train,[450,50])\n",
    "# train_dat = DataLoader(train, batch_size=2,collate_fn=collate_fn)\n",
    "# iter_dat = iter(train_dat)\n",
    "# first =next(iter_dat)[0]\n",
    "# print(first,len(first))\n",
    "# print(first.shape)\n",
    "# # cnn = Conv1d(in_channels = 69,out_channels = 256,kernel_size=7)\n",
    "# # output = cnn(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [1,2,3,4,5]\n",
    "# a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.one_hot(torch.arange(0, 5) % 3)\n",
    "# F.one_hot(torch.arange(0, 10), num_classes=5)\n",
    "# F.one_hot(torch.arange(0, 6).view(3,2) % 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [(torch.randint(0,70,(1014,)), 0, 1014 ) for i in range(5)]\n",
    "# print(data)\n",
    "# from torch.nn.functional import one_hot\n",
    "# examples, labels, lengths = zip(*data)\n",
    "# batch_size = len(examples)\n",
    "# length = len(examples[0])\n",
    "# vocab_size = 70\n",
    "# features = torch.zeros((batch_size, length,vocab_size))\n",
    "# for ind,example in enumerate(examples):\n",
    "#     features[ind,:,:] = one_hot(example)\n",
    "# return features.float(), labels.long(), lengths.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import label_binarize\n",
    "        # from torch.utils.data import TensorDataset, random_split\n",
    "        # dataset = load_dataset(\"dbpedia_14\")\n",
    "        # train = dataset['train']\n",
    "        # train = train.shuffle(seed=42)[:10000]\n",
    "        # test = dataset['test']\n",
    "        # test = test.shuffle(seed=42)[:10000]\n",
    "        # length = 1014\n",
    "        # train['content'] = [list(i.lower())[:length] + [' '] * (length - len(list(i.lower())[:length])) for i in tqdm(train['content'])]\n",
    "        # test['content'] = [list(i.lower())[:length] + [' '] * (length - len(list(i)[:length])) for i in tqdm(test['content'])]\n",
    "        # for i in train['content']:\n",
    "        #     if len(i) > length:\n",
    "        #         print(len(i))\n",
    "        #         print(i)\n",
    "        # labels = list(\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\|_@#$%^&*~`+=<>()[]{}\\n\")\n",
    "        # train['content'] = [label_binarize(i,classes=labels) for i in tqdm(train['content'])]\n",
    "        # print(\"Done character one hotting\")\n",
    "        # train['content'] = torch.tensor(np.array(train['content']))\n",
    "        # test['content'] = [label_binarize(i,classes=labels) for i in tqdm(test['content'])]\n",
    "        # test['content'] = torch.tensor(np.array(train['content']))\n",
    "        # train = TensorDataset(torch.transpose(train['content'],dim0=2,dim1=1).float(),torch.tensor(train['label']))\n",
    "        # self.mnist_test = TensorDataset(torch.transpose(test['content'],dim0=2,dim1=1).float(),torch.tensor(test['label']))\n",
    "        # self.mnist_train,self.mnist_val = random_split(train,[int(0.85*len(train)),len(train)-int(0.85*len(train))])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4549b9837ba6f6f3cb560dbe4d982b6fc570c62848458bd1fd6007ce703dacbf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ire1': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
